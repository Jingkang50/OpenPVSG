{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123f1b2d",
   "metadata": {},
   "source": [
    "# This is the script to summarize PVSG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4876c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VidOR:\n",
      "Number of subdirectories in ./vidor/frames/: 289\n",
      "Total number of PNG files in ./vidor/frames/: 69967\n",
      "Epic Kitchen\n",
      "Number of subdirectories in ./epic_kitchen/frames/: 55\n",
      "Total number of PNG files in ./epic_kitchen/frames/: 32985\n",
      "Ego4D\n",
      "Number of subdirectories in ./ego4d/frames/: 56\n",
      "Total number of PNG files in ./ego4d/frames/: 46536\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"./vidor/frames/\"\n",
    "\n",
    "# Count the number of subdirectories in root/vidor/frames/\n",
    "subdir_count = sum(os.path.isdir(os.path.join(root_dir, d)) for d in os.listdir(root_dir))\n",
    "\n",
    "# Count the number of PNG files in root/vidor/frames/\n",
    "png_count = sum(f.endswith('.png') for _, _, files in os.walk(root_dir) for f in files)\n",
    "\n",
    "print(f\"VidOR:\")\n",
    "print(f\"Number of subdirectories in {root_dir}: {subdir_count}\")\n",
    "print(f\"Total number of PNG files in {root_dir}: {png_count}\")\n",
    "\n",
    "\n",
    "root_dir = \"./epic_kitchen/frames/\"\n",
    "\n",
    "# Count the number of subdirectories in root/vidor/frames/\n",
    "subdir_count = sum(os.path.isdir(os.path.join(root_dir, d)) for d in os.listdir(root_dir))\n",
    "\n",
    "# Count the number of PNG files in root/vidor/frames/\n",
    "png_count = sum(f.endswith('.png') for _, _, files in os.walk(root_dir) for f in files)\n",
    "\n",
    "print(f\"Epic Kitchen\")\n",
    "print(f\"Number of subdirectories in {root_dir}: {subdir_count}\")\n",
    "print(f\"Total number of PNG files in {root_dir}: {png_count}\")\n",
    "\n",
    "\n",
    "root_dir = \"./ego4d/frames/\"\n",
    "\n",
    "# Count the number of subdirectories in root/vidor/frames/\n",
    "subdir_count = sum(os.path.isdir(os.path.join(root_dir, d)) for d in os.listdir(root_dir))\n",
    "\n",
    "# Count the number of PNG files in root/vidor/frames/\n",
    "png_count = sum(f.endswith('.png') for _, _, files in os.walk(root_dir) for f in files)\n",
    "\n",
    "print(f\"Ego4D\")\n",
    "print(f\"Number of subdirectories in {root_dir}: {subdir_count}\")\n",
    "print(f\"Total number of PNG files in {root_dir}: {png_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2967bac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149488"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "69967 + 32985 + 46536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad3e167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_files_in_dirs(base_dir):\n",
    "    \"\"\"Return a dictionary mapping each subdirectory of base_dir to the number of .png files it contains.\"\"\"\n",
    "    counts = {}\n",
    "    for dir_name in os.listdir(base_dir):\n",
    "        dir_path = os.path.join(base_dir, dir_name)\n",
    "        if os.path.isdir(dir_path):\n",
    "            count = sum(1 for file_name in os.listdir(dir_path) if file_name.endswith('.png'))\n",
    "            counts[dir_name] = count\n",
    "    return counts\n",
    "\n",
    "def distribute_dirs(counts, num_groups):\n",
    "    \"\"\"Distribute the directories among num_groups groups so that each group has approximately the same total count.\"\"\"\n",
    "    # Calculate the total number of files and the average number of files per group.\n",
    "    total_files = sum(counts.values())\n",
    "    avg_files_per_group = total_files / num_groups\n",
    "\n",
    "    # Sort the directories by the count in descending order.\n",
    "    sorted_dirs = sorted(counts, key=counts.get, reverse=True)\n",
    "\n",
    "    # Initialize an empty list for each group and a counter for the total number of files in each group.\n",
    "    groups = {i: [] for i in range(1, num_groups + 1)}\n",
    "    group_counts = {i: 0 for i in range(1, num_groups + 1)}\n",
    "\n",
    "    # Distribute the directories to the group with the smallest total count.\n",
    "    for dir_name in sorted_dirs:\n",
    "        # Find the group with the smallest total count.\n",
    "        min_group = min(group_counts, key=group_counts.get)\n",
    "        # Add the directory to the group and update the total count.\n",
    "        groups[min_group].append(dir_name)\n",
    "        group_counts[min_group] += counts[dir_name]\n",
    "        \n",
    "    return groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "368eefed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['725d6aca-b665-40cf-8b60-07d564c370aa', '181a2c5e-5b2c-4436-ba8d-26c7d7db4bb8', '90621e59-7800-49ab-aeb8-c7725f87a7d8', 'a05683ad-b4a2-4af6-94ab-b32bc7c97b79', '5c676dd6-d0d7-479d-b107-abf5857be8e0', 'c2e6d807-d903-4b64-98e1-2c07ca700c78_2', '92f8142a-25aa-444a-ae37-43fae4f95f18_1', '92f8142a-25aa-444a-ae37-43fae4f95f18_2', '0be30efe-9d71-4698-8304-f1d441aeea58_2', '6e0a6558-c212-4cab-b374-007671edb59c_1', '54097e7a-3a92-485e-a7d7-33d07b346d41'], 2: ['4e4f9d6e-7e27-4b14-81ab-60867cd418ad', 'a906a4c6-a0ad-41a3-ba79-59f151d955e4', 'ff5d68b9-8486-467d-ad87-93c31e7cdcca', '45e463b2-bdd5-407a-ab5c-8a5c5534e078', 'd1d4a1b3-a651-4eb8-bb7f-8d66982854fa', 'd2222009-a717-4b16-91ce-6399c5bb798a', 'dbeb569a-b3ff-47db-8189-fee05064cf20', '0be30efe-9d71-4698-8304-f1d441aeea58_1', '1bfe5ac2-cbf8-4364-8a30-60d97dd395df_1', 'e58a1cd6-cf82-4477-b8a3-8f749ebceffe_2', 'e2e4e68a-b464-4876-82ec-009b5a3cb257', 'e127fc34-0de5-41b0-ab68-7d5574bcf613'], 3: ['62a49b90-a91c-4263-8b4f-fb23879bd730', 'f1085fc6-4c8f-4ad2-9cd9-caa9dafe1b11', 'a95dcb11-e878-47c0-9a3a-c2252aae40ba', '85f21d37-73c8-42e8-bdda-1ff89dd6eb15', '03f2ed96-1719-427d-acf4-8bf504f1d66d', '29501ed1-77bb-4f53-aeb2-d062d5f568a9', '0cb2dd94-afb1-4e30-a62f-724f34d81777_1', '760a2d62-d580-4422-b32f-2c4fc9a35c7c_1', 'ec2e69c1-fd07-48ec-adff-0b2cf3ab25b6', 'eed8d8d7-6773-493b-af21-880f0acb063a', 'c20407ac-83d6-4c84-88cb-63bced9d456b'], 4: ['dfaa7536-3453-4eab-8d70-f1624d640060', 'a383d099-5eef-48b5-9d1b-5e2d97632725', '3751590f-3a97-4024-845b-b800e5df6166', '43b0205a-4e3c-46a7-9d1c-c04ead730180', '760a2d62-d580-4422-b32f-2c4fc9a35c7c_2', 'd62f9c1c-7d01-4350-a0fb-ec553dad8cf2', '0cb2dd94-afb1-4e30-a62f-724f34d81777_2', 'e58a1cd6-cf82-4477-b8a3-8f749ebceffe_1', '3b609b23-f91d-43da-9918-ce928181f53f', '6e0a6558-c212-4cab-b374-007671edb59c_2', 'c2e6d807-d903-4b64-98e1-2c07ca700c78_1'], 5: ['8be918b2-c819-4a84-98dc-5fe24835a4ac', 'b0df76ae-085a-4e4e-869a-61062dbb717f', '97eb4a18-87f2-47f2-9a67-11fca6bdae64', '5a163ffe-970a-4f67-a9e7-2ce340eaf6b1', 'ceda965f-3f19-4b80-ae6b-5256fee5f6aa', 'b275f09c-5dd2-4e8c-97de-edc1f0c8222b', '1bfe5ac2-cbf8-4364-8a30-60d97dd395df_3', '1bfe5ac2-cbf8-4364-8a30-60d97dd395df_2', '6f874e09-ea55-460c-8796-0ceae180bebc', 'c2e6d807-d903-4b64-98e1-2c07ca700c78_3', '22cc4d54-34be-4580-983a-9e710e831c16']}\n"
     ]
    }
   ],
   "source": [
    "base_dir = './ego4d/frames/'  # replace with your actual directory\n",
    "num_groups = 5\n",
    "counts = count_files_in_dirs(base_dir)\n",
    "groups = distribute_dirs(counts, num_groups)\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5831d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_groups(base_dir, groups):\n",
    "    \"\"\"Return a dictionary mapping each group to the total number of .png files in its directories.\"\"\"\n",
    "    group_counts = {}\n",
    "    for group, dirs in groups.items():\n",
    "        total = 0\n",
    "        for dir_name in dirs:\n",
    "            dir_path = os.path.join(base_dir, dir_name)\n",
    "            if os.path.isdir(dir_path):\n",
    "                count = sum(1 for file_name in os.listdir(dir_path) if file_name.endswith('.png'))\n",
    "                total += count\n",
    "        group_counts[group] = total\n",
    "    return group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0944b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 9253, 2: 9354, 3: 9264, 4: 9264, 5: 9401}\n"
     ]
    }
   ],
   "source": [
    "group_counts = count_files_in_groups(base_dir, groups)\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe0c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open('pvsg.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6dac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7581 1198 4151\n"
     ]
    }
   ],
   "source": [
    "instance = 0\n",
    "human_instance = 0\n",
    "relation_instance = 0\n",
    "\n",
    "for data_dict in data['data']:\n",
    "    instance += len(data_dict['objects'])\n",
    "    human_instance += len([object_dict for object_dict in data_dict['objects'] \n",
    "                           if object_dict['category'] in ['adult', 'baby', 'child']])\n",
    "    relation_instance += len(data_dict['relations'])\n",
    "    \n",
    "print(instance, human_instance, relation_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b003bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/lustre/jkyang/CVPR23/openpvsg\")\n",
    "\n",
    "from datasets import PVSGRelationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = '../data/'\n",
    "split = 'train'\n",
    "work_dir = f'../work_dirs/{split}_save_qf_1106'\n",
    "\n",
    "pvsg_rel_dataset = PVSGRelationDataset(f\"{data_dir}/pvsg.json\", split, work_dir)\n",
    "data_loader = DataLoader(pvsg_rel_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "918a2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_count = {i: 1 for i in range(65)}\n",
    "for i, relation_dict in enumerate(data_loader):\n",
    "    gt_relations = relation_dict['relations']\n",
    "    for gt_relation in gt_relations:\n",
    "        relation_count[int(gt_relation['relation'].item())] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7ada411",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for k, v in relation_count.items():\n",
    "    count.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa46be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131, 25, 56, 28, 37, 31, 11, 13, 32, 6, 41, 4, 18, 3, 15, 7, 4, 9, 1, 1, 1, 5, 7, 5, 851, 1, 20, 42, 275, 4, 2, 10, 31, 7, 3, 134, 62, 79, 802, 84, 5, 39, 36, 116, 7, 6, 20, 1, 1, 60, 11, 225, 6, 1, 199, 5, 18, 20, 32, 28, 130, 9, 126, 5, 30]\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13d1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/lustre/jkyang/CVPR23/openpvsg\")\n",
    "\n",
    "from datasets import PVSGRelationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = '../data/'\n",
    "split = 'val'\n",
    "work_dir = f'../work_dirs/{split}_save_qf_1106'\n",
    "\n",
    "pvsg_rel_dataset = PVSGRelationDataset(f\"{data_dir}/pvsg.json\", split, work_dir)\n",
    "data_loader = DataLoader(pvsg_rel_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eadc698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feats': tensor([[[[-1.0169, -0.8683, -0.9549,  ..., -0.3087,  0.3060,  0.0227],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-1.0594, -0.5338, -0.6702,  ...,  0.3208,  0.8226,  0.0628],\n",
      "          ...,\n",
      "          [-1.5996,  0.2630, -1.1823,  ..., -0.2304,  0.9076,  0.7807],\n",
      "          [-0.1954, -1.2839, -0.8114,  ..., -0.2264,  0.7319, -0.5872],\n",
      "          [-1.0849,  0.3828, -1.1044,  ..., -0.2720,  1.0115,  0.4702]],\n",
      "\n",
      "         [[-1.7796,  0.4645,  0.3554,  ...,  0.4280,  1.9627,  0.2822],\n",
      "          [-1.6237,  1.2218, -0.1845,  ...,  1.1305,  2.6389,  0.1401],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.2035, -0.3109, -2.0730,  ...,  0.4285, -0.8883, -0.6089],\n",
      "          [ 0.4158, -0.6314, -1.5116,  ..., -0.1546, -1.1967, -0.8004],\n",
      "          [ 0.9518, -0.5033, -2.1843,  ...,  0.0450, -1.0803, -0.1576],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
      "       dtype=torch.float64), 'relations': [{'subject_index': tensor([3]), 'object_index': tensor([0]), 'relation': tensor([62]), 'relation_span': tensor([[1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)}, {'subject_index': tensor([3]), 'object_index': tensor([0]), 'relation': tensor([54]), 'relation_span': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
      "         0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)}, {'subject_index': tensor([3]), 'object_index': tensor([23]), 'relation': tensor([51]), 'relation_span': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "         1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "       dtype=torch.float64)}, {'subject_index': tensor([5]), 'object_index': tensor([2]), 'relation': tensor([51]), 'relation_span': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)}], 'pairs': [[tensor([3]), tensor([0])], [tensor([3]), tensor([0])], [tensor([3]), tensor([23])], [tensor([5]), tensor([2])]]}\n"
     ]
    }
   ],
   "source": [
    "for i, relation_dict in enumerate(data_loader):\n",
    "    print(relation_dict)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a7036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5db55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_dir = '../data/'\n",
    "pvsg_data = json.load(open(f\"{data_dir}/pvsg.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "babe4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = []\n",
    "split = 'train'\n",
    "for data_source in ['vidor', 'epic_kitchen', 'ego4d']:\n",
    "    for video_id in pvsg_data['split'][data_source][split]:\n",
    "        video_ids.append(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c6ccd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {}\n",
    "for relation in pvsg_data['relations']:\n",
    "    relation_dict[relation] = 0\n",
    "\n",
    "for data in pvsg_data['data']:\n",
    "    if data['video_id'] in video_ids:\n",
    "        for relation in data['relations']:\n",
    "            relation_dict[relation[2]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "909cdf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biting 2\n",
      "brushing 2\n",
      "carrying 1\n",
      "cleaning 3\n",
      "climbing 0\n",
      "cooking 2\n",
      "drinking 0\n",
      "eating 1\n",
      "enclosing 0\n",
      "entering 1\n",
      "feeding 0\n",
      "getting down on 1\n",
      "going down 2\n",
      "guiding 0\n",
      "hanging from 0\n",
      "holdoing 1\n",
      "hugging 3\n",
      "jumping from 0\n",
      "jumping over 1\n",
      "licking 0\n",
      "lighting 0\n",
      "over 0\n",
      "playing 0\n",
      "pointing to 0\n",
      "pulling 4\n",
      "putting 0\n",
      "shaking hand with 0\n",
      "squatting on 0\n",
      "squeezing 0\n",
      "stepping on 0\n",
      "stirring 0\n",
      "swinging 1\n",
      "watering 0\n"
     ]
    }
   ],
   "source": [
    "for k, v in relation_dict.items():\n",
    "    if v < 5:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "303f0077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0004_11566980553',\n",
       " '0010_8610561401',\n",
       " '0018_4748191834',\n",
       " '0027_4571353789',\n",
       " '0028_4021064662',\n",
       " '0039_6951351121',\n",
       " '0046_11919433184',\n",
       " '0051_3702633786',\n",
       " '0053_5599511471',\n",
       " '0054_2612939953',\n",
       " '0057_7001078933',\n",
       " '0062_6430774273',\n",
       " '0069_2740320945',\n",
       " '0075_11566764085',\n",
       " '0096_5296138427',\n",
       " '1000_6828150903',\n",
       " '1001_7007447516',\n",
       " '1002_5280626374',\n",
       " '1005_4760962392',\n",
       " '1005_7031128593',\n",
       " '1005_7401573420',\n",
       " '1006_4580824633',\n",
       " '1007_6631583821',\n",
       " '1011_4633647136',\n",
       " '1012_4024008346',\n",
       " '1015_4698622422',\n",
       " '1017_3056841458',\n",
       " '1019_3768851893',\n",
       " '1020_2471845614',\n",
       " '1021_3478653250',\n",
       " '1021_4278168115',\n",
       " '1025_4615486172',\n",
       " '1025_6244382586',\n",
       " '1052_8530515192',\n",
       " '1100_9117425466',\n",
       " '1122_3393449055',\n",
       " '1124_9861436503',\n",
       " '1161_5895320023',\n",
       " '1164_6895784766',\n",
       " '1203_8316378691',\n",
       " 'P01_03',\n",
       " 'P02_10',\n",
       " 'P03_06',\n",
       " 'P04_27',\n",
       " 'P05_05',\n",
       " 'P08_07',\n",
       " 'P09_07',\n",
       " 'P11_11',\n",
       " 'P14_06',\n",
       " 'P19_06',\n",
       " 'P28_19',\n",
       " '0be30efe-9d71-4698-8304-f1d441aeea58_1',\n",
       " '1bfe5ac2-cbf8-4364-8a30-60d97dd395df_1',\n",
       " '22cc4d54-34be-4580-983a-9e710e831c16',\n",
       " '43b0205a-4e3c-46a7-9d1c-c04ead730180',\n",
       " '6e0a6558-c212-4cab-b374-007671edb59c_2',\n",
       " '8be918b2-c819-4a84-98dc-5fe24835a4ac',\n",
       " 'c20407ac-83d6-4c84-88cb-63bced9d456b',\n",
       " 'c2e6d807-d903-4b64-98e1-2c07ca700c78_2',\n",
       " 'd1d4a1b3-a651-4eb8-bb7f-8d66982854fa',\n",
       " 'd2222009-a717-4b16-91ce-6399c5bb798a',\n",
       " 'eed8d8d7-6773-493b-af21-880f0acb063a']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openpvsg]",
   "language": "python",
   "name": "conda-env-openpvsg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

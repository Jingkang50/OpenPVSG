{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "sys.path.append(\"/mnt/lustre/jkyang/CVPR23/openpvsg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PVSGRelationAnnotation:\n",
    "    def __init__(self, anno_file, split='train'):\n",
    "        with open(anno_file, \"r\") as f:\n",
    "            anno = json.load(f)\n",
    "\n",
    "        self.video_ids = []\n",
    "        for data_source in ['vidor', 'epic_kitchen', 'ego4d']:\n",
    "            for video_id in anno['split'][data_source][split]:\n",
    "                self.video_ids.append(video_id)\n",
    "        \n",
    "        self.classes = anno['objects']['thing'] + anno['objects']['stuff']\n",
    "        self.relations = anno['relations']\n",
    "\n",
    "        self.videos = {}\n",
    "        for video_anno in anno['data']:\n",
    "            self.videos[video_anno['video_id']] = video_anno\n",
    "\n",
    "    def __getitem__(self, vid):\n",
    "        assert vid in self.videos\n",
    "        video_info = copy.deepcopy(self.videos[vid])\n",
    "\n",
    "        object_list, relation_list = [], []\n",
    "        for object_content in video_info['objects']:\n",
    "            object_content[\"category\"] = self.classes.index(object_content[\"category\"])\n",
    "            object_list.append(object_content)\n",
    "\n",
    "        for relation_content in video_info['relations']:\n",
    "            relation_content[2] = self.relations.index(relation_content[2])\n",
    "            relation_list.append(relation_content)\n",
    "\n",
    "        return {'video_id': vid, 'objects': object_list, \n",
    "                'relations': relation_list, 'relation_str': self.videos[vid]['relations']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "split = 'val'\n",
    "pvsg_dataset = PVSGRelationAnnotation(f\"{data_dir}/pvsg.json\", split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = f'../work_dirs/{split}_save_qf_1106'\n",
    "data_dir = '../data/'\n",
    "vid = 'P01_03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_feats = load_pickle(f\"{work_dir}/{vid}/query_feats.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pred Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools.mask as mask_utils\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "def get_pred_mask_tubes_one_video(vid, work_dir):\n",
    "    labels = []\n",
    "    results = []\n",
    "\n",
    "    # Read mask labels from the file\n",
    "    label_path = f\"{work_dir}/{vid}/quantitive/masks.txt\"\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            labels.append(line.strip().split())\n",
    "\n",
    "    # Decode mask labels\n",
    "    for label in labels:\n",
    "        frame_id, track_id, cid, h, w, m = label\n",
    "        rle = {'size': (int(h), int(w)), 'counts': m}\n",
    "        mask = mask_utils.decode(rle)\n",
    "        results.append(dict(fid=frame_id, tid=track_id, mask=mask, cid=cid))\n",
    "\n",
    "    # Sort data by 'tid' key\n",
    "    def key_func(k):\n",
    "        return k['tid']\n",
    "    results = sorted(results, key=key_func)\n",
    "\n",
    "    # Group by tid\n",
    "    masks_grp_by_tid = {}\n",
    "    for key, value in groupby(results, key_func):\n",
    "        masks_grp_by_tid[key] = list(value)\n",
    "    \n",
    "    # Organize masks into tubes\n",
    "    pred_mask_tubes = {}\n",
    "    for key in masks_grp_by_tid.keys():\n",
    "        class_ids = []\n",
    "        mask_list = []\n",
    "        for content in masks_grp_by_tid[key]:\n",
    "            mask_list.append({int(content['fid']) - 1: content['mask']})\n",
    "            class_ids.append(content['cid'])\n",
    "        count = Counter(class_ids)\n",
    "        tube_class, _ = count.most_common(1)[0]\n",
    "        pred_mask_tubes[int(key)] = {'cid': tube_class, 'mask': mask_list}\n",
    "    \n",
    "    return pred_mask_tubes\n",
    "\n",
    "# Usage\n",
    "pred_mask_tubes = get_pred_mask_tubes_one_video(vid, work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(o, precision=2):\n",
    "    \"\"\"Convert size in bytes to a more readable format.\"\"\"\n",
    "    size = deep_getsizeof(o, set())\n",
    "    suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "    suffix_index = 0\n",
    "    while size >= 1024 and suffix_index < len(suffixes)-1:\n",
    "        # Increase the suffix index and reduce the size\n",
    "        suffix_index += 1 \n",
    "        size /= 1024.0\n",
    "    return f\"{size:.{precision}f} {suffixes[suffix_index]}\"\n",
    "\n",
    "def deep_getsizeof(o, ids=set()):\n",
    "    \"\"\" Recursively finds size of objects \"\"\"\n",
    "    if id(o) in ids:\n",
    "        return 0\n",
    "\n",
    "    ids.add(id(o))\n",
    "\n",
    "    size = sys.getsizeof(o)\n",
    "    if isinstance(o, dict):\n",
    "        size += sum([deep_getsizeof(k, ids) + deep_getsizeof(v, ids) for k, v in o.items()])\n",
    "\n",
    "    elif hasattr(o, '__dict__'):\n",
    "        size += deep_getsizeof(o.__dict__, ids)\n",
    "\n",
    "    elif hasattr(o, '__iter__') and not isinstance(o, (str, bytes, bytearray)):\n",
    "        size += sum([deep_getsizeof(i, ids) for i in o])\n",
    "\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.34 MB'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_size(pred_mask_tubes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ranges(frames):\n",
    "    # this function converts list into a range\n",
    "    sorted_frames = sorted(frames)\n",
    "    new_ranges = []\n",
    "    range_start = sorted_frames[0]\n",
    "    for i in range(1, len(sorted_frames)):\n",
    "        if sorted_frames[i] - sorted_frames[i - 1] + 1 > 4:\n",
    "            if sorted_frames[i - 1] - range_start >= 4:\n",
    "                new_ranges.append([range_start, sorted_frames[i - 1]])\n",
    "            range_start = sorted_frames[i]\n",
    "    if sorted_frames[-1] - range_start >= 4:\n",
    "        new_ranges.append([range_start, sorted_frames[-1]])\n",
    "\n",
    "    return new_ranges\n",
    "\n",
    "def calculate_iou(gt_mask, pred_mask):\n",
    "    # This is a placeholder function. You should implement the actual IOU calculation here.\n",
    "    # It should return the Intersection over Union of two masks.\n",
    "    intersection = np.logical_and(gt_mask, pred_mask).sum()\n",
    "    union = np.logical_or(gt_mask, pred_mask).sum()\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_and_process_gt_tubes(vid, pvsg_dataset, pred_mask_tubes):\n",
    "    # Determine the data source\n",
    "    if vid.startswith('P'):\n",
    "        data_source = 'epic_kitchen'\n",
    "    elif vid.split('_')[0].isdigit() and len(vid.split('_')[0]) == 4:\n",
    "        data_source = 'vidor'\n",
    "    else:\n",
    "        data_source = 'ego4d'\n",
    "        \n",
    "    gt_masks_root_vid = os.path.join(data_dir, data_source, 'masks', vid)\n",
    "\n",
    "    matching_dict = {}\n",
    "    object_list = pvsg_dataset[vid]['objects']\n",
    "    \n",
    "    for frame_id, mask_path in enumerate(sorted(Path(gt_masks_root_vid).rglob(\"*.png\"))):\n",
    "        pan_mask = np.array(Image.open(mask_path))\n",
    "\n",
    "        for object_entry in object_list:\n",
    "            instance_id = object_entry['object_id']\n",
    "            cid = object_entry['category']\n",
    "\n",
    "            # Process the GT mask for this frame\n",
    "            gt_mask = (pan_mask == instance_id).astype(bool)\n",
    "\n",
    "            # Prepare candidate prediction masks with the same cid\n",
    "            candidate_pred_tubes = {pred_id: pred_tube for pred_id, pred_tube in pred_mask_tubes.items() \n",
    "                                    if int(pred_tube['cid']) == int(cid)}\n",
    "\n",
    "            for pred_id, pred_tube in candidate_pred_tubes.items():\n",
    "                # Find overlapping frames\n",
    "                pred_frames = set(map(lambda x: list(x.keys())[0], pred_tube['mask']))\n",
    "                if frame_id in pred_frames:\n",
    "                    pred_mask = next(item for item in pred_tube['mask'] if list(item.keys())[0] == frame_id)[frame_id]\n",
    "                    iou = calculate_iou(gt_mask, pred_mask)\n",
    "                    \n",
    "                    if iou > 0.5:\n",
    "                        if instance_id not in matching_dict:\n",
    "                            matching_dict[instance_id] = {pred_id: [frame_id]}\n",
    "                        else:\n",
    "                            if pred_id not in matching_dict[instance_id]:\n",
    "                                matching_dict[instance_id][pred_id] = [frame_id]\n",
    "                            else:\n",
    "                                matching_dict[instance_id][pred_id].append(frame_id)\n",
    "\n",
    "    return matching_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dict = match_and_process_gt_tubes(vid, pvsg_dataset, pred_mask_tubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ranges(num_list):\n",
    "    ranges = []\n",
    "    start = num_list[0]\n",
    "    for i in range(1, len(num_list)):\n",
    "        if num_list[i] > num_list[i-1] + 5:\n",
    "            end = num_list[i-1]\n",
    "            ranges.append(f'{start}-{end}')\n",
    "            start = num_list[i]\n",
    "    # Add the last range\n",
    "    ranges.append(f'{start}-{num_list[-1]}')\n",
    "    return ranges\n",
    "    \n",
    "    \n",
    "def process_data(data):\n",
    "    processed_data = {}\n",
    "\n",
    "    for outer_key, inner_dict in data.items():\n",
    "        processed_inner = {}\n",
    "        for inner_key, number_list in inner_dict.items():\n",
    "            # Rule 2: Delete the inner key if the list has fewer than 5 numbers\n",
    "            if len(number_list) < 5:\n",
    "                continue\n",
    "\n",
    "            # Rule 1: If there's only one inner key, convert the list to a range string\n",
    "            if len(inner_dict) == 1:\n",
    "                min_val, max_val = min(number_list), max(number_list)\n",
    "                processed_inner[inner_key] = f'{min_val}-{max_val}'\n",
    "            else:\n",
    "                # Sorting the list to ensure continuity\n",
    "                sorted_num_list = sorted(number_list)\n",
    "                processed_inner[inner_key] = find_ranges(sorted_num_list)\n",
    "\n",
    "        if processed_inner:\n",
    "            processed_data[outer_key] = processed_inner\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matching_dict = process_data(matching_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_relations = pvsg_dataset[vid]['relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26, 20, 39, [[55, 67], [347, 357]]],\n",
       " [26, 20, 10, [[96, 112], [360, 366]]],\n",
       " [26, 36, 24, [[65, 128], [258, 360]]],\n",
       " [26, 50, 24, [[73, 89]]],\n",
       " [26, 31, 24, [[92, 128]]],\n",
       " [26, 66, 24, [[158, 165]]],\n",
       " [26, 46, 24, [[167, 176]]],\n",
       " [26, 4, 60, [[175, 214]]],\n",
       " [26, 33, 24, [[240, 255]]],\n",
       " [26, 15, 39, [[384, 402]]],\n",
       " [26, 23, 24, [[395, 410], [576, 583]]],\n",
       " [26, 53, 24, [[425, 475], [489, 493]]],\n",
       " [26, 53, 39, [[476, 490]]],\n",
       " [26, 35, 24, [[496, 573]]]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_gt_relations(matching_dict, gt_relations):\n",
    "    translated_relations = []\n",
    "\n",
    "    def time_overlap(range1, range2):\n",
    "        # This function checks if two ranges overlap and returns the overlapping range\n",
    "        return [max(range1[0], range2[0]), min(range1[1], range2[1])]\n",
    "\n",
    "    def is_valid_range(range1):\n",
    "        # This function checks if the start of the range is less than the end\n",
    "        return range1[0] < range1[1]\n",
    "    \n",
    "    def merge_sublists(lst):\n",
    "        merged_list = []\n",
    "        temp_dict = {}\n",
    "        for sublist in lst:\n",
    "            # Extract the key (first three items) and value (fourth item)\n",
    "            key = tuple(sublist[:-1])\n",
    "            value = sublist[-1]\n",
    "\n",
    "            # If key is already in dictionary, append the value to the existing entry\n",
    "            if key in temp_dict:\n",
    "                temp_dict[key].append(value)\n",
    "            else:\n",
    "                # Otherwise, create a new entry with this value in a list\n",
    "                temp_dict[key] = [value]\n",
    "\n",
    "        # Convert the dictionary back into a list with merged items\n",
    "        for key, values in temp_dict.items():\n",
    "            merged_list.append(list(key) + [values])\n",
    "\n",
    "        return merged_list\n",
    "    \n",
    "    for relation in gt_relations:\n",
    "        tube_1, tube_2, label, time_ranges = relation\n",
    "        if tube_1 not in matching_dict or tube_2 not in matching_dict:\n",
    "            continue\n",
    "        tube_1_ranges = matching_dict[tube_1]\n",
    "        tube_2_ranges = matching_dict[tube_2]\n",
    "\n",
    "        for time_range in time_ranges:\n",
    "            for inner_key_1, ranges_1 in tube_1_ranges.items():\n",
    "                if isinstance(ranges_1, str):  # convert string range to list\n",
    "                    ranges_1 = [ranges_1]\n",
    "                for range_str_1 in ranges_1:\n",
    "                    start_1, end_1 = map(int, range_str_1.split('-'))\n",
    "                    for inner_key_2, ranges_2 in tube_2_ranges.items():\n",
    "                        if isinstance(ranges_2, str):  # convert string range to list\n",
    "                            ranges_2 = [ranges_2]\n",
    "                        for range_str_2 in ranges_2:\n",
    "                            start_2, end_2 = map(int, range_str_2.split('-'))\n",
    "                            overlap_1 = time_overlap(time_range, [start_1, end_1 + 1])\n",
    "                            overlap_2 = time_overlap(time_range, [start_2, end_2 + 1])\n",
    "                            overlap_both = time_overlap(overlap_1, overlap_2)\n",
    "                            # Check if there is an overlap and the overlap is valid\n",
    "                            if is_valid_range(overlap_both):\n",
    "                                # Append the overlap, inner keys, and label to the translated relations\n",
    "                                translated_relations.append([inner_key_1, inner_key_2, label, overlap_both])\n",
    "                                \n",
    "    return merge_sublists(translated_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_relations = translate_gt_relations(matching_dict, gt_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1548, 1555, 39, [[55, 56], [62, 67], [347, 351]]],\n",
       " [1548, 1554, 39, [[355, 357]]],\n",
       " [1548, 1555, 10, [[96, 104], [110, 111]]],\n",
       " [1548, 1554, 10, [[360, 362]]],\n",
       " [1548,\n",
       "  1550,\n",
       "  24,\n",
       "  [[65, 77],\n",
       "   [85, 113],\n",
       "   [122, 128],\n",
       "   [258, 275],\n",
       "   [290, 331],\n",
       "   [347, 357],\n",
       "   [489, 493]]],\n",
       " [1585, 1550, 24, [[267, 290]]],\n",
       " [1548, 1557, 24, [[158, 165]]],\n",
       " [1548, 1547, 60, [[194, 198], [205, 214]]],\n",
       " [1585, 1547, 60, [[201, 202]]],\n",
       " [1548, 1594, 24, [[253, 255]]],\n",
       " [1548, 1599, 24, [[576, 579]]],\n",
       " [1548, 1601, 24, [[461, 473]]],\n",
       " [1548, 1550, 39, [[476, 490]]],\n",
       " [1548, 1607, 24, [[500, 563]]]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_feat_tubes = {}\n",
    "for idx, query_feat in enumerate(query_feats):\n",
    "    pred_feat_tubes[query_feats[idx].track_id] = query_feats[idx].qf_tube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feats(pred_feat_tubes, d=256):\n",
    "    video_length = len(pred_feat_tubes[list(pred_feat_tubes.keys())[0]])\n",
    "    output_list = []\n",
    "    for tube_id in pred_feat_tubes.keys():\n",
    "        new_feat_tube = np.zeros([video_length, d])\n",
    "        for frame_id in range(video_length):\n",
    "            if pred_feat_tubes[tube_id][frame_id] is not None:\n",
    "                new_feat_tube[frame_id] = pred_feat_tubes[tube_id][frame_id]['query_feat']\n",
    "                \n",
    "        tube_dict = {tube_id: new_feat_tube}\n",
    "        output_list.append(tube_dict)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feats_and_relations(pred_relations, pred_feat_tubes, d=256):\n",
    "    \"\"\"\n",
    "    Process predicted relations and features to generate a list of dictionaries containing\n",
    "    relation information and features for each subject-object pair across the video frames.\n",
    "\n",
    "    Parameters:\n",
    "    - pred_relations: A list of tuples containing relation information \n",
    "        (subject index, object index, relation type, time span).\n",
    "    - pred_feat_tubes: A list of lists containing feature information for each frame and each tube.\n",
    "    - d: The dimensionality of the feature vectors (default is 256).\n",
    "\n",
    "    Returns:\n",
    "    - output_list: A list of dictionaries with keys 'relation', 'tube_s', 'tube_o', and 'relation_span'.\n",
    "    \"\"\"\n",
    "\n",
    "    output_list = []\n",
    "        \n",
    "    for item in pred_relations:\n",
    "        tube_s_index, tube_o_index, relation, time_span = item\n",
    "        video_length = len(pred_feat_tubes[list(pred_feat_tubes.keys())[0]])\n",
    "        \n",
    "        relation_span = np.zeros(video_length)\n",
    "        for span_range in time_span:\n",
    "            for i in range(span_range[0], span_range[1]):\n",
    "                relation_span[i] = 1\n",
    "        \n",
    "        # processing subject feature\n",
    "        for frame_id in range(video_length):\n",
    "            if pred_feat_tubes[tube_s_index][frame_id] is None:\n",
    "                relation_span[frame_id] = 0\n",
    "                \n",
    "        # processing object feature\n",
    "        for frame_id in range(video_length):\n",
    "            if pred_feat_tubes[tube_o_index][frame_id] is None:\n",
    "                relation_span[frame_id] = 0\n",
    "        \n",
    "        # ignore those without long relation span\n",
    "        if sum(relation_span) >= 3:\n",
    "            output_dict = {\n",
    "                'relation': relation,\n",
    "                'relation_span': relation_span,\n",
    "            }\n",
    "\n",
    "            output_list.append(output_dict)\n",
    "    \n",
    "    return {\"feats\": process_feats(pred_feat_tubes), \"relation\": output_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = process_feats_and_relations(pred_relations, pred_feat_tubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90.75 MB'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_size(relation_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fce9c5bcfd7b67e9f16f6541f3136b566aec82f163f97996541f8fb70e7c49dd"
  },
  "kernelspec": {
   "display_name": "Python [conda env:openpvsg]",
   "language": "python",
   "name": "conda-env-openpvsg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
